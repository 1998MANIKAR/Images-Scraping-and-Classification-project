{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60188b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Useful Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras import optimizers\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import os\n",
    "from os import listdir\n",
    "import os\n",
    "import random\n",
    "import scipy\n",
    "import pylab as pl\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f0010f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_data_dir=r'C:\\Users\\User\\Downloads\\Images'\n",
    "validation_data_dir=r'C:\\Users\\User\\Downloads\\Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1229b09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the Number of classes in the training folder\n",
    "file = os.listdir(r\"C:\\Users\\User\\Downloads\\Images\")\n",
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d7faf",
   "metadata": {},
   "source": [
    "### Loading Some Scrapped Image Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample images which I have scrapped \n",
    "import matplotlib.image as mpimg\n",
    "Jeans_train=r\"C:\\Users\\User\\Downloads\\Images\\Jeans(men)\"\n",
    "Saree_train=r\"C:\\Users\\User\\Downloads\\Images\\saree\"\n",
    "Trouser_train=r\"C:\\Users\\User\\Downloads\\Images\\Trousers(Men)\"\n",
    "\n",
    "\n",
    "Dir_train=[Jeans_train, Saree_train, Trouser_train]\n",
    "for dirs in Dir_train:\n",
    "    k=listdir(dirs)\n",
    "    for i in k[:2]:\n",
    "        img=mpimg.imread('{}/{}'.format(dirs,i))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab43e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Dimensions for the image to be input and then loading the images\n",
    "input_shape=(576,576,3)\n",
    "img_width=576\n",
    "img_height=576\n",
    "nb_train_samples=192\n",
    "nb_validation_samples=48\n",
    "batch_size=8\n",
    "epoch=150"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d448f414",
   "metadata": {},
   "source": [
    "### Preparing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38730b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Generator( Data Augmentation on Training Images)\n",
    "\n",
    "Train_generator_augmented=ImageDataGenerator(rescale=1./255,\n",
    "                                             zoom_range=0.2,\n",
    "                                             rotation_range=30,\n",
    "                                             horizontal_flip=True)\n",
    "Train_generator=Train_generator_augmented.flow_from_directory(Train_data_dir,\n",
    "                                                              target_size=(img_width,img_height),\n",
    "                                                              batch_size=batch_size, \n",
    "                                                              class_mode='categorical')\n",
    "\n",
    "# Validation Data Generator\n",
    "Data_gen=ImageDataGenerator(rescale=1./255)\n",
    "validation_generator=Data_gen.flow_from_directory(validation_data_dir,\n",
    "                                                  target_size=(img_width,img_height),\n",
    "                                                  batch_size=batch_size, \n",
    "                                                  class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1cdbe2",
   "metadata": {},
   "source": [
    "### Defining the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b295dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "model=Sequential()\n",
    "\n",
    "# First convolution layer\n",
    "model.add(Conv2D(32,(3,3),input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Second convolution layer\n",
    "model.add(Conv2D(32,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Third convolution layer\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# Fourth convolution layer\n",
    "model.add(Conv2D(64,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e43e2",
   "metadata": {},
   "source": [
    "### Defining Early stopping and Model check point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f15289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Early stopping and Model check point\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "ES = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30)\n",
    "MC = ModelCheckpoint('Image_Classification.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19e20cd",
   "metadata": {},
   "source": [
    "### Fitting the data into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e48de03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Training Data\n",
    "history = model.fit_generator(\n",
    "    Train_generator, \n",
    "    epochs=epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples//batch_size,\n",
    "    steps_per_epoch=nb_train_samples//batch_size,\n",
    "    callbacks=[ES,MC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15bfe712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "evl=model.evaluate(validation_generator,steps=1)\n",
    "print(\"Test Loss\",evl[0])\n",
    "print(\"Test Accuracy\",evl[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd5ffd",
   "metadata": {},
   "source": [
    "### On 43 Epoch itself the val_accuracy is: 93.76% and val_loss: 43.95%,thus saving the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a339ad1b",
   "metadata": {},
   "source": [
    "### saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d9861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the best model where val_accuracy is maximum.\n",
    "model.save('Image_Classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf697327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 150 Epochs Summary\n",
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4791e8",
   "metadata": {},
   "source": [
    "### Visualizing Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d68a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing  Training\n",
    "import matplotlib.pyplot as plt\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(30, 12))\n",
    "ax1.plot(history.history['loss'], color='b', label=\"Training loss\")\n",
    "ax1.plot(history.history['val_loss'], color='r', label=\"validation loss\")\n",
    "ax1.set_xticks(np.arange(1, epoch, 1),)\n",
    "ax1.set_xlabel('Epochs' ,fontsize=50)\n",
    "ax1.set_ylabel('Loss' ,fontsize=50)\n",
    "ax1.legend(loc='best', shadow=True)\n",
    "\n",
    "ax2.plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\n",
    "ax2.plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
    "ax2.set_xlabel('Epochs' ,fontsize=50)\n",
    "ax2.set_ylabel('Accuracy' ,fontsize=50)\n",
    "ax2.set_xticks(np.arange(1, epoch, 1))\n",
    "\n",
    "ax2.legend(loc='best', shadow=True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c3868c",
   "metadata": {},
   "source": [
    "### As we can see that accuracy is increasing and losses are decreasing as number of epochs are increasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ead38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As we can see that there are 3 classes for the 144 test images\n",
    "print(validation_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9be4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets load our model\n",
    "\n",
    "saved_model = load_model('Image_Classification.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cef116",
   "metadata": {},
   "source": [
    "### Predicting Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8d64bd",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Predicted samples of the test images\n",
    "test_jeans=r\"C:\\Users\\User\\Downloads\\Images\\Jeans(men)\"\n",
    "test_Saree=r\"C:\\Users\\User\\Downloads\\Images\\saree\"\n",
    "test_trouser=r\"C:\\Users\\User\\Downloads\\Images\\Trousers(Men)\"\n",
    "\n",
    "\n",
    "Predicted_class=[]\n",
    "classes=[test_jeans,test_Saree,test_trouser]\n",
    "for test_dir in classes:\n",
    "    for i in listdir(test_dir):\n",
    "        print(\"Input Image is:\",i)\n",
    "        img= image.load_img('{}/{}'.format(test_dir,i))                         \n",
    "        test_image = image.load_img('{}/{}'.format(test_dir,i),target_size=(576, 576))\n",
    "        test_image = image.img_to_array(test_image)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        test_image = np.expand_dims(test_image, axis=0)\n",
    "        result = saved_model.predict(test_image)\n",
    "        final=np.argmax(result, axis=1)[0]\n",
    "        if final==0:\n",
    "            print(\"Predicted Label is: jeans\\n\")\n",
    "            Predicted_class.append(\"Jeans men\")\n",
    "        elif final==1:\n",
    "            print(\"Predicted Label is: sarees\\n\")\n",
    "            Predicted_class.append(\"Sarees\")\n",
    "        elif final==2:\n",
    "            print(\"Predicted Label is: trouser\\n\")\n",
    "            Predicted_class.append(\"trouser men\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b6ceb7",
   "metadata": {},
   "source": [
    "### DataFrame to show the Actual and Predicted Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813a5c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame()\n",
    "res['Predicted_Label']=Predicted_class\n",
    "res['Actual_Label']=validation_generator.classes\n",
    "res[\"Actual_Label\"] = res[\"Actual_Label\"].replace({0: 'jeans men', 1: 'Sarees',2:'Trouser men'})\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0b43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
